{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Conv1DStudent.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "PcahCqill_TM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 1d Convolutional Neural Networks"
      ]
    },
    {
      "metadata": {
        "id": "5juHZFcFugzS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# Imports\n",
        "import numpy as np\n",
        "import os\n",
        "# from utils.utilities import *\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Bx9AXfRcmGky",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### About the Data"
      ]
    },
    {
      "metadata": {
        "id": "8-uE2dd9mJMv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Data is from people doing one of these activities (WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING) <br><br>\n",
        "The data is from a smartphone and provides the body acceleration, general acceleration and a gyroscope reading <br><br>\n",
        "Data is from: https://archive.ics.uci.edu/ml/datasets/human+activity+recognition+using+smartphones "
      ]
    },
    {
      "metadata": {
        "id": "gHFlVzfY4ZPQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Read in data from functions provided below"
      ]
    },
    {
      "metadata": {
        "id": "ikIjLu7w4Mm_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train, labels_train, list_ch_train = read_data_train() # train\n",
        "X_test, labels_test, list_ch_test = read_data_test()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EG3Tq1ajmjOu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eabe3b8a-11a6-4c95-a6be-64b7328284c4"
      },
      "cell_type": "code",
      "source": [
        "print(X_train.shape)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7352, 128, 9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MwRtb-8ymqDz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### Explaining the shape of the data \n",
        "There are 7,352 data points that are classified as doing one of those activities <br>\n",
        "There are 128 time steps <br>\n",
        "There are 9 values for each time step for each data point for the x,y,z values of the body \n",
        "acceleration, general acceleration and gyrscope reading. <br>"
      ]
    },
    {
      "metadata": {
        "id": "V-8mOh7cm75k",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Use train_test_split to create training and validation data and labels"
      ]
    },
    {
      "metadata": {
        "id": "buuR3HH9yTOw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train, X_val, lab_train, lab_val = train_test_split(X_train, labels_train, random_state=123)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "roTpeSQMnKHa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "One hot coding is when each row represents one label and it the nonzero column represents what the label is<br>\n",
        " [0,0,0,0,0,1] <br>\n",
        "           ^ This label is LAYING, which was previously represented with a 5\n",
        "           <br><br>"
      ]
    },
    {
      "metadata": {
        "id": "0LiLobJZnscs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### One hot encoding functions are provided at the bottom of this notebook <br> Use these functions to convert the training, validation and testing labels"
      ]
    },
    {
      "metadata": {
        "id": "gZQJY0rYnKeC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_train = one_hot(lab_train)\n",
        "y_val = one_hot(lab_val)\n",
        "y_test = one_hot(labels_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7bi9-LMuotEG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Define your Keras model <br>\n",
        "You wlil want to use\n",
        "\n",
        "See for examples on creating Keras modelshttps://github.com/keras-team/keras/blob/master/examples/mnist_cnn.py"
      ]
    },
    {
      "metadata": {
        "id": "9mwwpV8upQYD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "c706c62f-eb4d-454c-c8e5-b7711f96848d"
      },
      "cell_type": "code",
      "source": [
        "# fill in with your code below\n",
        "model = keras.models.Sequential()\n",
        "model.add(keras.layers.Convolution1D(filters=18, kernel_size=3, strides = 1, activation = \"relu\", input_shape=X_train[0].shape))\n",
        "model.add(keras.layers.GlobalMaxPooling1D()) # or keras.layers.MaxPooling1D(pool_size=2, padding=\"valid\")\n",
        "model.add(keras.layers.Dense(6, activation=\"sigmoid\")) \n",
        "print(model.summary())  # view model"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_1 (Conv1D)            (None, 126, 18)           504       \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_1 (Glob (None, 18)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 6)                 114       \n",
            "=================================================================\n",
            "Total params: 618\n",
            "Trainable params: 618\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "X844AtBlqV1Y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Compile your model"
      ]
    },
    {
      "metadata": {
        "id": "6KSPl0lMqUUZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lr =  0.0008\n",
        "model.compile( optimizer=tf.train.AdamOptimizer(lr), loss=keras.losses.categorical_crossentropy, metrics = ['accuracy'] )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pBOK_ZaCq6XR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Fit your model"
      ]
    },
    {
      "metadata": {
        "id": "6ksWXRzrrCzL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        },
        "outputId": "c473d9b6-fecf-46b3-fdbf-2694bd3135ad"
      },
      "cell_type": "code",
      "source": [
        "history = model.fit( X_train,\n",
        "                    y_train,\n",
        "                    epochs= 100,\n",
        "                    batch_size= 600,\n",
        "                    validation_data=(X_test, y_val),\n",
        "                    verbose=1 \n",
        "                    )"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-3f426b3ee404>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m600\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m                     )\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1291\u001b[0m           \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1292\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1293\u001b[0;31m           steps=validation_steps)\n\u001b[0m\u001b[1;32m   1294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1295\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mvalidation_split\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;36m0.\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mvalidation_split\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split)\u001b[0m\n\u001b[1;32m    919\u001b[0m       ]\n\u001b[1;32m    920\u001b[0m       \u001b[0;31m# Check that all arrays have the same length.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m       \u001b[0mtraining_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_array_lengths\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_graph_network\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m         \u001b[0;31m# Additional checks to avoid users mistakenly using improper loss fns.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/engine/training_utils.pyc\u001b[0m in \u001b[0;36mcheck_array_lengths\u001b[0;34m(inputs, targets, weights)\u001b[0m\n\u001b[1;32m    283\u001b[0m                      \u001b[0;34m'the same number of samples as target arrays. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m                      \u001b[0;34m'Found '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' input samples '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m                      'and ' + str(list(set_y)[0]) + ' target samples.')\n\u001b[0m\u001b[1;32m    286\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset_w\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m     raise ValueError('All sample_weight arrays should have '\n",
            "\u001b[0;31mValueError\u001b[0m: Input arrays should have the same number of samples as target arrays. Found 2947 input samples and 1838 target samples."
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "2YXazeH8udoG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Code below prints the test loss and accuracy <br>\n",
        "### Before you print your accuracy and loss, play around with the parameters!!"
      ]
    },
    {
      "metadata": {
        "id": "k0e7vQOO5w90",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a8c1a5f1-c943-4a67-b796-b9218328a06e"
      },
      "cell_type": "code",
      "source": [
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Test loss:', 0.3925280878411983)\n",
            "('Test accuracy:', 0.8612147947064812)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0oQd_q-LxEi8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "42UVWm_wxEf5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DRsI4XwYxFgK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Provided Functions Below"
      ]
    },
    {
      "metadata": {
        "id": "adnPCq9PuTBq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def read_data_train():\n",
        "  \"\"\" Read data \"\"\"\n",
        "\n",
        "  # Fixed params\n",
        "  n_class = 6\n",
        "  n_steps = 128\n",
        "\n",
        "  label_path = 'https://raw.githubusercontent.com/BeaverWorksMedlytics/datasets/master/week2_conv1d/y_train.txt'\n",
        "  labels = pd.read_csv(label_path, header = None)\n",
        "\n",
        "  list_of_channels = ['body_acc_x', 'body_acc_y', 'body_acc_z', 'body_gyro_x',\n",
        "  'body_gyro_y', 'body_gyro_z', 'total_acc_x', 'total_acc_y', 'total_acc_z']\n",
        "\n",
        "  X = np.zeros((len(labels), n_steps, len(list_of_channels)))\n",
        "\n",
        "  label_path = 'https://raw.githubusercontent.com/BeaverWorksMedlytics/datasets/master/week2_conv1d/IntertialSignals/body_acc_x_train.txt'\n",
        "  dat_ = pd.read_csv(label_path, delim_whitespace = True, header = None)\n",
        "  X[:,:,0] = dat_.as_matrix()\n",
        "\n",
        "  label_path = 'https://raw.githubusercontent.com/BeaverWorksMedlytics/datasets/master/week2_conv1d/IntertialSignals/body_acc_y_train.txt'\n",
        "  dat_ = pd.read_csv(label_path, delim_whitespace = True, header = None)\n",
        "  X[:,:,1] = dat_.as_matrix()\n",
        "\n",
        "  label_path = 'https://raw.githubusercontent.com/BeaverWorksMedlytics/datasets/master/week2_conv1d/IntertialSignals/body_acc_z_train.txt'\n",
        "  dat_ = pd.read_csv(label_path, delim_whitespace = True, header = None)\n",
        "  X[:,:,2] = dat_.as_matrix()\n",
        "\n",
        "  label_path = 'https://raw.githubusercontent.com/BeaverWorksMedlytics/datasets/master/week2_conv1d/IntertialSignals/body_gyro_x_train.txt'\n",
        "  dat_ = pd.read_csv(label_path, delim_whitespace = True, header = None)\n",
        "  X[:,:,3] = dat_.as_matrix()\n",
        "\n",
        "  label_path = 'https://raw.githubusercontent.com/BeaverWorksMedlytics/datasets/master/week2_conv1d/IntertialSignals/body_gyro_y_train.txt'\n",
        "  dat_ = pd.read_csv(label_path, delim_whitespace = True, header = None)\n",
        "  X[:,:,4] = dat_.as_matrix()\n",
        "\n",
        "  label_path = 'https://raw.githubusercontent.com/BeaverWorksMedlytics/datasets/master/week2_conv1d/IntertialSignals/body_gyro_z_train.txt'\n",
        "  dat_ = pd.read_csv(label_path, delim_whitespace = True, header = None)\n",
        "  X[:,:,5] = dat_.as_matrix()\n",
        "\n",
        "  label_path = 'https://raw.githubusercontent.com/BeaverWorksMedlytics/datasets/master/week2_conv1d/IntertialSignals/total_acc_x_train.txt'\n",
        "  dat_ = pd.read_csv(label_path, delim_whitespace = True, header = None)\n",
        "  X[:,:,6] = dat_.as_matrix()\n",
        "\n",
        "  label_path = 'https://raw.githubusercontent.com/BeaverWorksMedlytics/datasets/master/week2_conv1d/IntertialSignals/total_acc_y_train.txt'\n",
        "  dat_ = pd.read_csv(label_path, delim_whitespace = True, header = None)\n",
        "  X[:,:,7] = dat_.as_matrix()\n",
        "\n",
        "  label_path = 'https://raw.githubusercontent.com/BeaverWorksMedlytics/datasets/master/week2_conv1d/IntertialSignals/total_acc_z_train.txt'\n",
        "  dat_ = pd.read_csv(label_path, delim_whitespace = True, header = None)\n",
        "  X[:,:,8] = dat_.as_matrix()\n",
        "\n",
        "\n",
        "  # Return \n",
        "  return X, labels[0].values, list_of_channels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iDJBOkx9x0HZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def read_data_test():\n",
        "  \"\"\" Read data \"\"\"\n",
        "\n",
        "  # Fixed params\n",
        "  n_class = 6\n",
        "  n_steps = 128\n",
        "\n",
        "  label_path = 'https://raw.githubusercontent.com/BeaverWorksMedlytics/datasets/master/week2_conv1d/y_test.txt'\n",
        "  labels = pd.read_csv(label_path, header = None)\n",
        "\n",
        "  list_of_channels = ['body_acc_x', 'body_acc_y', 'body_acc_z', 'body_gyro_x',\n",
        "  'body_gyro_y', 'body_gyro_z', 'total_acc_x', 'total_acc_y', 'total_acc_z']\n",
        "\n",
        "  X = np.zeros((len(labels), n_steps, len(list_of_channels)))\n",
        "\n",
        "  label_path = 'https://raw.githubusercontent.com/BeaverWorksMedlytics/datasets/master/week2_conv1d/IntertialSignals/body_acc_x_test.txt'\n",
        "  dat_ = pd.read_csv(label_path, delim_whitespace = True, header = None)\n",
        "  X[:,:,0] = dat_.as_matrix()\n",
        "\n",
        "  label_path = 'https://raw.githubusercontent.com/BeaverWorksMedlytics/datasets/master/week2_conv1d/IntertialSignals/body_acc_y_test.txt'\n",
        "  dat_ = pd.read_csv(label_path, delim_whitespace = True, header = None)\n",
        "  X[:,:,1] = dat_.as_matrix()\n",
        "\n",
        "  label_path = 'https://raw.githubusercontent.com/BeaverWorksMedlytics/datasets/master/week2_conv1d/IntertialSignals/body_acc_z_test.txt'\n",
        "  dat_ = pd.read_csv(label_path, delim_whitespace = True, header = None)\n",
        "  X[:,:,2] = dat_.as_matrix()\n",
        "\n",
        "  label_path = 'https://raw.githubusercontent.com/BeaverWorksMedlytics/datasets/master/week2_conv1d/IntertialSignals/body_gyro_x_test.txt'\n",
        "  dat_ = pd.read_csv(label_path, delim_whitespace = True, header = None)\n",
        "  X[:,:,3] = dat_.as_matrix()\n",
        "\n",
        "  label_path = 'https://raw.githubusercontent.com/BeaverWorksMedlytics/datasets/master/week2_conv1d/IntertialSignals/body_gyro_y_test.txt'\n",
        "  dat_ = pd.read_csv(label_path, delim_whitespace = True, header = None)\n",
        "  X[:,:,4] = dat_.as_matrix()\n",
        "\n",
        "  label_path = 'https://raw.githubusercontent.com/BeaverWorksMedlytics/datasets/master/week2_conv1d/IntertialSignals/body_gyro_z_test.txt'\n",
        "  dat_ = pd.read_csv(label_path, delim_whitespace = True, header = None)\n",
        "  X[:,:,5] = dat_.as_matrix()\n",
        "\n",
        "  label_path = 'https://raw.githubusercontent.com/BeaverWorksMedlytics/datasets/master/week2_conv1d/IntertialSignals/total_acc_x_test.txt'\n",
        "  dat_ = pd.read_csv(label_path, delim_whitespace = True, header = None)\n",
        "  X[:,:,6] = dat_.as_matrix()\n",
        "\n",
        "  label_path = 'https://raw.githubusercontent.com/BeaverWorksMedlytics/datasets/master/week2_conv1d/IntertialSignals/total_acc_y_test.txt'\n",
        "  dat_ = pd.read_csv(label_path, delim_whitespace = True, header = None)\n",
        "  X[:,:,7] = dat_.as_matrix()\n",
        "\n",
        "  label_path = 'https://raw.githubusercontent.com/BeaverWorksMedlytics/datasets/master/week2_conv1d/IntertialSignals/total_acc_z_test.txt'\n",
        "  dat_ = pd.read_csv(label_path, delim_whitespace = True, header = None)\n",
        "  X[:,:,8] = dat_.as_matrix()\n",
        "\n",
        "\n",
        "  # Return \n",
        "  return X, labels[0].values, list_of_channels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wrog_9co1HhG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def one_hot(labels, n_class = 6):\n",
        "\t\"\"\" One-hot encoding \"\"\"\n",
        "\texpansion = np.eye(n_class)\n",
        "\ty = expansion[:, labels-1].T\n",
        "\tassert y.shape[1] == n_class, \"Wrong number of labels!\"\n",
        "\n",
        "\treturn y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EYft5h8x1IbU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_batches(X, y, batch_size = 100):\n",
        "\t\"\"\" Return a generator for batches \"\"\"\n",
        "\tn_batches = len(X) // batch_size\n",
        "\tX, y = X[:n_batches*batch_size], y[:n_batches*batch_size]\n",
        "\n",
        "\t# Loop over batches and yield\n",
        "\tfor b in range(0, len(X), batch_size):\n",
        "\t\tyield X[b:b+batch_size], y[b:b+batch_size]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Sfwx7f1icYwo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}